
@inbook{varga_apache_2016,
	location = {Berkeley, {CA}},
	title = {Apache Kafka as a Messaging Hub},
	isbn = {978-1-4842-2195-2 978-1-4842-2196-9},
	url = {http://link.springer.com/10.1007/978-1-4842-2196-9_12},
	pages = {187--201},
	booktitle = {Creating Maintainable {APIs}},
	publisher = {Apress},
	author = {Varga, Ervin},
	bookauthor = {Varga, Ervin},
	urldate = {2021-11-29},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-1-4842-2196-9_12},
	file = {Varga - 2016 - Apache Kafka as a Messaging Hub.pdf:/Users/d067617/Zotero/storage/UVQEEBWA/Varga - 2016 - Apache Kafka as a Messaging Hub.pdf:application/pdf},
}

@inproceedings{ma_iip_2010,
	location = {San Jose, California},
	title = {{IIP}: an event-based platform for {ITS} applications},
	isbn = {978-1-4503-0429-0},
	url = {http://portal.acm.org/citation.cfm?doid=1899441.1899443},
	doi = {10.1145/1899441.1899443},
	shorttitle = {{IIP}},
	abstract = {In this paper, we propose an event-based platform in support of developing Intelligent Transportation System ({ITS}) applications, especially applications compatible with the {IntelliDriveSM} environment. Essentially, it combines two components, i.e. the {IIP} Cloud Component and the {IIP} Client Component. The {IIP} Cloud Component provides canonical publish/subscribe (pub/sub) functions to both traffic management facilities and mobile nodes. The {IIP} Client Component provides mobile nodes with pub/sub functions which allow them to communicate with the {IIP} Cloud Component as well as with each other. We show that by leveraging heterogeneous data sources and various communication mechanisms in the {ITS} environment, {IIP} supports a wide variety of {ITS} applications.},
	eventtitle = {the Second International Workshop},
	pages = {1},
	booktitle = {Proceedings of the Second International Workshop on Computational Transportation Science - {IWCTS} '10},
	publisher = {{ACM} Press},
	author = {Ma, Shuo and Wolfson, Ouri and Lin, Jie},
	urldate = {2021-11-29},
	date = {2010},
	langid = {english},
	file = {Ma et al. - 2010 - IIP an event-based platform for ITS applications.pdf:/Users/d067617/Zotero/storage/IBD7QQSH/Ma et al. - 2010 - IIP an event-based platform for ITS applications.pdf:application/pdf},
}

@article{dogac_semantically_2004,
	title = {Semantically enriched web services for the travel industry},
	volume = {33},
	issn = {0163-5808},
	url = {https://dl.acm.org/doi/10.1145/1031570.1031575},
	doi = {10.1145/1031570.1031575},
	abstract = {Today, the travel information services are dominantly provided by Global Distribution Systems ({GDS}). The Global Distribution Systems provide access to real time availability and price information for ﬂights, hotels and car rental companies. However {GDSs} have legacy architectures with private networks, specialized hardware, limited speed and search capabilities. Furthermore, being legacy systems, it is very diﬃcult to interoperate them with other systems and data sources. For these reasons, Web service technology is an ideal ﬁt for travel information systems.},
	pages = {21--27},
	number = {3},
	journaltitle = {{ACM} {SIGMOD} Record},
	shortjournal = {{SIGMOD} Rec.},
	author = {Dogac, A. and Kabak, Y. and Laleci, G. and Sinir, S. and Yildiz, A. and Kirbas, S. and Gurcan, Y.},
	urldate = {2021-11-29},
	date = {2004-09},
	langid = {english},
	keywords = {semantics, Messaging, {XML} Schemas},
	file = {Dogac et al. - 2004 - Semantically enriched web services for the travel .pdf:/Users/d067617/Zotero/storage/TEGHBMMJ/Dogac et al. - 2004 - Semantically enriched web services for the travel .pdf:application/pdf},
}

@book{zangemeister_nutzwertanalyse_2014,
	location = {Winnemark, Germany},
	edition = {5. Auflage, erweitert},
	title = {Nutzwertanalyse in der Systemtechnik: eine Methodik zur multidimensionalen Bewertung und Auswahl von Projektalternativen},
	isbn = {978-3-923264-00-1},
	shorttitle = {Nutzwertanalyse in der Systemtechnik},
	pagetotal = {414},
	publisher = {Prof. Dr.-Ing. Christof Zangemeister},
	author = {Zangemeister, Christof},
	date = {2014},
	keywords = {(stw)Scoring-Modell, (stw)Systems Engineering, Nutzwertanalyse, Systemtechnik},
	file = {Table of Contents PDF:/Users/d067617/Zotero/storage/66KKYJVS/Zangemeister - 2014 - Nutzwertanalyse in der Systemtechnik eine Methodi.pdf:application/pdf},
}

@article{rupp_requirements_2009,
	title = {Requirements Engineering und Management},
	volume = {46},
	issn = {2198-2775},
	url = {https://doi.org/10.1007/BF03340367},
	doi = {10.1007/BF03340367},
	abstract = {Requirements Engineering und Management gewinnen in allen Bereichen der Systementwicklung stetig an Bedeutung. Zusammenhänge zwischen der Qualität der Anforderungserhebung und des Projekterfolges, wie von der Standish Group im jährlich erscheinenden Chaos Report [Standish 2004] untersucht, sind den meisten ein Begriff. Bei der Erhebung von Anforderungen treten immer wieder ähnliche Probleme auf. Dabei spielen unterschiedliche Faktoren und Gegebenheiten eine Rolle, die beachtet werden müssen. Es gibt mehrere Möglichkeiten, die Tücken der Analysephase zu meistern; eine Hilfe bietet der Einsatz der in diesem Artikel vorgestellten Methoden zur Anforderungserhebung. Auch wenn die Anforderungen korrekt und vollständig erhoben sind, ist es eine Kunst, diese zu verwalten. In der heutigen Zeit der verteilten Projekte ist es eine Herausforderung, die Dokumentation für jeden Beteiligten ständig verfügbar, nachvollziehbar und eindeutig zu erhalten. Requirements Management rüstet den Analytiker mit Methoden aus, um sich dieser Herausforderung zu stellen. Änderungen von Stakeholder-Wünschen an bestehenden Anforderungen stellen besondere Ansprüche an das Requirements Management, doch mithilfe eines Change-Management-Prozesses können auch diese bewältigt werden. Metriken und Traceability unterstützen bei der Aufwandsabschätzung für Änderungsanträge.},
	pages = {94--103},
	number = {3},
	journaltitle = {{HMD} Praxis der Wirtschaftsinformatik},
	shortjournal = {{HMD}},
	author = {Rupp, Chris and Simon, Matthias and Hocker, Florian},
	urldate = {2021-11-07},
	date = {2009-06-01},
	file = {Springer Full Text PDF:/Users/d067617/Zotero/storage/WHT27JM7/Rupp et al. - 2009 - Requirements Engineering und Management.pdf:application/pdf},
}

@book{kees_open_2015,
	title = {Open source enterprise software},
	publisher = {Springer},
	author = {Kees, Alexandra},
	date = {2015},
	file = {Full Text:/Users/d067617/Zotero/storage/PJE3N493/Kees - 2015 - Open source enterprise software.pdf:application/pdf;Snapshot:/Users/d067617/Zotero/storage/NWEJHGXP/10.html:text/html},
}

@article{g_b_high_2021,
	title = {High Resilient Messaging Service for Microservice Architecture},
	volume = {16},
	issn = {0973-9769, 0973-4562},
	url = {http://ripublication.com/ijaer21/ijaerv16n5_04.pdf},
	doi = {10.37622/IJAER/16.5.2021.357-361},
	abstract = {Fundamental structure of a software system is called software architecture. Software architectures are helpful in systematic software development. One such software architecture is microservice architecture. This architecture breaks down the entire software system into smaller components each of which work independently. The microservice architecture is being widely adapted in software industries due to its reliability, scalability and easier maintenance. But breaking down a system into smaller, independent components that use different tech stacks and message formats gives rise to complex communication between the components. This paper proposes a new messaging service that allows communication between services with ease. The new messaging service uses distributed streaming platforms like Apache Kafka to decouple the messaging between services. It also uses Apache Camel to provide functionalities such as message schema transformation and schema validation; these functionalities allow the services to communicate with each other with only a few lines of code. The result is a new state of the art messaging service that can be easily integrated with producer and consumer services. The paper also discusses where the new messaging service is more suitable. The performance metric used here is the number of additional lines of code required on the producer or consumer side for using this messaging service. The results are, almost thirty percent to sixty percent reduction of code required for integration on the producer side and nine percent to forty percent reduction of code required for integration on the consumer side.},
	pages = {357},
	number = {5},
	journaltitle = {International Journal of Applied Engineering Research},
	author = {G. B., Sanjana and N. S., Girish Rao Salanke},
	urldate = {2021-11-07},
	date = {2021-05-30},
	keywords = {Apache Camel, Apache Kafka, Messaging, Message Schemas, Schemas, Confluent Schema Registry, Schema Registry},
	file = {G. B. and N. S. - 2021 - High Resilient Messaging Service for Microservice .pdf:/Users/d067617/Zotero/storage/78K8BXWT/G. B. and N. S. - 2021 - High Resilient Messaging Service for Microservice .pdf:application/pdf},
}

@article{ranjan_radar-base_2019,
	title = {{RADAR}-Base: Open Source Mobile Health Platform for Collecting, Monitoring, and Analyzing Data Using Sensors, Wearables, and Mobile Devices},
	volume = {7},
	url = {https://mhealth.jmir.org/2019/8/e11734},
	doi = {10.2196/11734},
	shorttitle = {{RADAR}-Base},
	abstract = {Background: With a wide range of use cases in both research and clinical domains, collecting continuous mobile health ({mHealth}) streaming data from multiple sources in a secure, highly scalable, and extensible platform is of high interest to the open source {mHealth} community. The European Union Innovative Medicines Initiative Remote Assessment of Disease and Relapse-Central Nervous System ({RADAR}-{CNS}) program is an exemplary project with the requirements to support the collection of high-resolution data at scale; as such, the Remote Assessment of Disease and Relapse ({RADAR})-base platform is designed to meet these needs and additionally facilitate a new generation of {mHealth} projects in this nascent field. Objective: Wide-bandwidth networks, smartphone penetrance, and wearable sensors offer new possibilities for collecting near-real-time high-resolution datasets from large numbers of participants. The aim of this study was to build a platform that would cater for large-scale data collection for remote monitoring initiatives. Key criteria are around scalability, extensibility, security, and privacy. Methods: {RADAR}-base is developed as a modular application; the backend is built on a backbone of the highly successful Confluent/Apache Kafka framework for streaming data. To facilitate scaling and ease of deployment, we use Docker containers to package the components of the platform. {RADAR}-base provides 2 main mobile apps for data collection, a Passive App and an Active App. Other third-Party Apps and sensors are easily integrated into the platform. Management user interfaces to support data collection and enrolment are also provided. Results: General principles of the platform components and design of {RADAR}-base are presented here, with examples of the types of data currently being collected from devices used in {RADAR}-{CNS} projects: Multiple Sclerosis, Epilepsy, and Depression cohorts. Conclusions: {RADAR}-base is a fully functional, remote data collection platform built around Confluent/Apache Kafka and provides off-the-shelf components for projects interested in collecting {mHealth} datasets at scale.},
	pages = {e11734},
	number = {8},
	journaltitle = {{JMIR} {mHealth} and {uHealth}},
	author = {Ranjan, Yatharth and Rashid, Zulqarnain and Stewart, Callum and Conde, Pauline and Begale, Mark and Verbeeck, Denny and Boettcher, Sebastian and Hyve, The and Dobson, Richard and Folarin, Amos and Consortium, The {RADAR}-{CNS}},
	urldate = {2021-11-07},
	date = {2019-08-01},
	keywords = {Apache Kafka, Messaging, Schemas, Confluent Schema Registry, Schema Registry, Apache Avro, Generic Schema Registry},
	file = {Full Text:/Users/d067617/Zotero/storage/26CPFEJM/Ranjan et al. - 2019 - RADAR-Base Open Source Mobile Health Platform for.pdf:application/pdf;Snapshot:/Users/d067617/Zotero/storage/BYUZ39UD/e11734.html:text/html;ranjan radar-base.pdf:/Users/d067617/Zotero/storage/GE7PBPLB/ranjan radar-base.pdf:application/pdf},
}

@article{holom_metadata_2020,
	title = {Metadata management in a big data infrastructure},
	volume = {42},
	issn = {2351-9789},
	url = {https://www.sciencedirect.com/science/article/pii/S2351978920306247},
	doi = {10.1016/j.promfg.2020.02.060},
	series = {International Conference on Industry 4.0 and Smart Manufacturing ({ISM} 2019)},
	abstract = {The adoption of the Internet of Things ({IoT}) in industry provides the opportunity to gather valuable data. Nevertheless, this amount of data must be analyzed to identify patterns in the data, model behaviors of equipment and to enable prediction. Although big data found its initiation already some years ago, there are still many challenges to be solved, e.g. metadata representation and management are still a research topic. The big data architecture of the {RISC} data analytics framework relies on the combination of big data technologies with semantic approaches, to process and store large volumes of data from heterogeneous sources, provided by {FILL}, which is a key machine tool provider. The proposed architecture is capable of handling sensor data using big data technologies such as Spark on Hadoop, {InfluxDB} and Elasticsearch. The metadata representation and management approach is adopted in order to define the structure and the relations (i.e., the connections) between the various data sources provided by the sensors and logging information system. On the other hand, using a metadata approach in our big data environment enhances {RISC} data analytics framework by making it generic, reusable and responsive in case of changes, thus keeping the data lakes up-to-date and ensuring the validity of the analytics results. The work presented here is part of an ongoing project ({BOOST} 4.0) currently addressed under the {EU} H2020 program.},
	pages = {375--382},
	journaltitle = {Procedia Manufacturing},
	shortjournal = {Procedia Manufacturing},
	author = {Holom, Roxana-Maria and Rafetseder, Katharina and Kritzinger, Stefanie and Sehrschön, Harald},
	urldate = {2021-11-07},
	date = {2020-01-01},
	keywords = {big data, data harmonization, linked data, machine learning, metadata, semantics, Apache Avro},
	file = {ScienceDirect Full Text PDF:/Users/d067617/Zotero/storage/J4CS8LQ3/Holom et al. - 2020 - Metadata management in a big data infrastructure.pdf:application/pdf},
}

@article{do_matching_2007,
	title = {Matching large schemas: Approaches and evaluation},
	volume = {32},
	issn = {03064379},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306437906000780},
	doi = {10.1016/j.is.2006.09.002},
	shorttitle = {Matching large schemas},
	abstract = {Current schema matching approaches still have to improve for large and complex Schemas. The large search space increases the likelihood for false matches as well as execution times. Further difﬁculties for Schema matching are posed by the high expressive power and versatility of modern schema languages, in particular user-deﬁned types and classes, component reuse capabilities, and support for distributed schemas and namespaces. To better assist the user in matching complex schemas, we have developed a new generic schema matching tool, {COMA}++, providing a library of individual matchers and a ﬂexible infrastructure to combine the matchers and reﬁne their results. Different match strategies can be applied including a new scalable approach to identify context-dependent correspondences between schemas with shared elements and a fragment-based match approach which decomposes a large match task into smaller tasks. We conducted a comprehensive evaluation of the match strategies using large e-Business standard schemas. Besides providing helpful insights for future match implementations, the evaluation demonstrated the practicability of our system for matching large schemas.},
	pages = {857--885},
	number = {6},
	journaltitle = {Information Systems},
	shortjournal = {Information Systems},
	author = {Do, Hong-Hai and Rahm, Erhard},
	urldate = {2021-11-29},
	date = {2007-09},
	langid = {english},
	keywords = {Schemas, {XML} Schemas},
	file = {Do and Rahm - 2007 - Matching large schemas Approaches and evaluation.pdf:/Users/d067617/Zotero/storage/GU44N5ND/Do and Rahm - 2007 - Matching large schemas Approaches and evaluation.pdf:application/pdf},
}

@inproceedings{li_semantic_2004,
	location = {Orlando, {FL}},
	title = {Semantic message oriented middleware for publish/subscribe networks},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.548172},
	doi = {10.1117/12.548172},
	abstract = {The publish/subscribe paradigm of Message Oriented Middleware provides a loosely coupled communication model between distributed applications. Traditional publish/subscribe middleware uses keywords to match advertisements and subscriptions and does not support deep semantic matching. To this end, we designed and implemented a Semantic Message Oriented Middleware system to provide such capabilities for semantic description and matching. We adopted the {DARPA} Agent Markup Language and Ontology Inference Layer, a formal knowledge representation language for expressing sophisticated classifications and enabling automated inference, as the topic description language in our middleware system. A simple description logic inference system was implemented to handle the matching process between the subscriptions of subscribers and the advertisements of publishers. Moreover our middleware system also has a security architecture to support secure communication and user privilege control.},
	eventtitle = {Defense and Security},
	pages = {124},
	author = {Li, Han and Jiang, Guofei},
	editor = {Carapezza, Edward M.},
	urldate = {2021-11-29},
	date = {2004-09-15},
	langid = {english},
	keywords = {semantics, Message Schemas},
	file = {Li and Jiang - 2004 - Semantic message oriented middleware for publishs.pdf:/Users/d067617/Zotero/storage/4S94WHDP/Li and Jiang - 2004 - Semantic message oriented middleware for publishs.pdf:application/pdf},
}

@inproceedings{radchenko_micro-workflows_2018,
	title = {Micro-workflows: Kafka and kepler fusion to support digital twins of industrial processes},
	shorttitle = {Micro-workflows},
	pages = {83--88},
	booktitle = {2018 {IEEE}/{ACM} International Conference on Utility and Cloud Computing Companion ({UCC} Companion)},
	publisher = {{IEEE}},
	author = {Radchenko, Gleb and Alaasam, Ameer {BA} and Tchernykh, Andrei},
	date = {2018},
	keywords = {Apache Kafka, Schemas, Confluent Schema Registry, Schema Registry, Apache Avro},
	file = {Snapshot:/Users/d067617/Zotero/storage/83CRN6AA/8605762.html:text/html;Radchenko et al. - 2018 - Micro-workflows Kafka and kepler fusion to suppor.pdf:/Users/d067617/Zotero/storage/6SSP43RG/Radchenko et al. - 2018 - Micro-workflows Kafka and kepler fusion to suppor.pdf:application/pdf},
}

@inproceedings{crapo_semantically_2009,
	location = {Denver, {CO}},
	title = {The Semantically Enabled Smart Grid},
	eventtitle = {Grid-Interop},
	booktitle = {The Road to an Interoperable Grid},
	author = {Crapo, Andrew and Wang, Xiaofeng and Lizzi, John and Larson, Ron},
	date = {2009},
	keywords = {semantics, Messaging, Schemas, {XML} Schemas},
	file = {Full Text:/Users/d067617/Zotero/storage/6QVC39CN/Crapo et al. - 2009 - The semantically enabled smart grid.pdf:application/pdf},
}

@inproceedings{duftler_web_2001,
	title = {Web Services Invocation Framework ({WSIF})},
	volume = {194},
	pages = {49},
	booktitle = {{OOPSLA} Workshop on Object Oriented Web Services},
	author = {Duftler, Matthew J. and Mukhi, Nirmal K. and Slominski, Aleksander and Weerawarana, Sanjiva},
	date = {2001},
	file = {Full Text:/Users/d067617/Zotero/storage/FDDVSI2D/Duftler et al. - 2001 - Web services invocation framework (wsif).pdf:application/pdf},
}

@thesis{dessalegn_muruts_multi-tenant_2016,
	title = {Multi-Tenant Apache Kafka for Hops: Kafka Topic-Based Multi-Tenancy and {ACL}-Based Authorization for Hops},
	shorttitle = {Multi-Tenant Apache Kafka for Hops},
	type = {M.Sc. Thesis},
	author = {Dessalegn Muruts, Misganu},
	date = {2016},
	keywords = {Apache Kafka, Thesis, Confluent Schema Registry, Apache Avro, Generic Schema Registry},
	file = {Full Text:/Users/d067617/Zotero/storage/2L6H6GVG/Dessalegn Muruts - 2016 - Multi-Tenant Apache Kafka for Hops Kafka Topic-Ba.pdf:application/pdf},
}

@thesis{korhonen_using_2019,
	title = {Using Kafka to Build Scalable and Fault Tolerant Systems},
	type = {B.Sc. Thesis},
	author = {Korhonen, Teemu},
	date = {2019},
	keywords = {Apache Kafka, Thesis, Confluent Schema Registry, Schema Registry, Apache Avro},
	file = {Full Text:/Users/d067617/Zotero/storage/BKEKYPHP/Korhonen - 2019 - Using Kafka to build scalable and fault tolerant s.pdf:application/pdf},
}

@inproceedings{heery_metadata_2003,
	title = {Metadata schema registries in the partially Semantic Web: the {CORES} experience},
	shorttitle = {Metadata schema registries in the partially Semantic Web},
	pages = {11--18},
	booktitle = {International Conference on Dublin Core and Metadata Applications},
	author = {Heery, Rachel and Johnston, Pete and Fülöp, Csaba and Micsik, András},
	date = {2003},
	keywords = {semantics, Schemas, Schema Registry},
	file = {Full Text:/Users/d067617/Zotero/storage/FWPZAXWK/Heery et al. - 2003 - Metadata schema registries in the partially Semant.pdf:application/pdf;Snapshot:/Users/d067617/Zotero/storage/L68RVMQ3/729.html:text/html},
}

@inproceedings{kreps_kafka_2011,
	title = {Kafka: A distributed messaging system for log processing},
	volume = {11},
	shorttitle = {Kafka},
	pages = {1--7},
	booktitle = {Proceedings of the {NetDB}},
	author = {Kreps, Jay and Narkhede, Neha and Rao, Jun},
	date = {2011},
	keywords = {Apache Kafka, Confluent Schema Registry, Schema Registry, Seminal Work},
	file = {Kreps et al. - Kafka a Distributed Messaging System for Log Proc.pdf:/Users/d067617/Zotero/storage/IHW7MDYA/Kreps et al. - Kafka a Distributed Messaging System for Log Proc.pdf:application/pdf;Full Text:/Users/d067617/Zotero/storage/E6IITQEA/Kreps et al. - 2011 - Kafka A distributed messaging system for log proc.pdf:application/pdf},
}

@inproceedings{muller_iot_2017,
	title = {{IoT} for All: Architectural design of an extensible and lightweight {IoT} analytics platform},
	shorttitle = {{IoT} for All},
	pages = {11--13},
	booktitle = {Proceedings of the 2017 International Conference on Industrial Engineering and Systems Management ({IESM}), Saarbrücken, Germane},
	author = {Müller, Stephan and Wiener, Patrick and Bürger, Adrian and Nimis, Jens and Bousonville, V. F. T. and Melo, T. and Rezg, N.},
	date = {2017},
	keywords = {Apache Kafka, Schemas, Confluent Schema Registry, Schema Registry},
	file = {Müller et al. - IoT for All Architectural Design of an Extensible.pdf:/Users/d067617/Zotero/storage/5VSG53NV/Müller et al. - IoT for All Architectural Design of an Extensible.pdf:application/pdf;Full Text:/Users/d067617/Zotero/storage/6DJMV48X/Müller et al. - 2017 - IoT for All Architectural design of an extensible.pdf:application/pdf},
}

@thesis{jephte_extract_2021,
	title = {Extract, Transform, and Load data from Legacy Systems to Azure Cloud},
	type = {Internship Report},
	author = {Jephte, Ioudom Foubi},
	date = {2021},
	keywords = {Apache Kafka, Confluent Schema Registry, Schema Registry, Internship Report},
	file = {Jephte - Extract, Transform, and Load data from Legacy Syst.pdf:/Users/d067617/Zotero/storage/KH2WQL5A/Jephte - Extract, Transform, and Load data from Legacy Syst.pdf:application/pdf;Full Text:/Users/d067617/Zotero/storage/9N52N5Z2/Jephte - 2021 - Extract, Transform, and Load data from Legacy Syst.pdf:application/pdf;Snapshot:/Users/d067617/Zotero/storage/4GMDSIZG/118629.html:text/html},
}

@thesis{auer_distributed_2017,
	title = {Distributed data store for internet of things environments},
	type = {B.Sc. Thesis},
	author = {Auer, Jonas},
	date = {2017},
	keywords = {Apache Kafka, Thesis, Confluent Schema Registry, Schema Registry},
	file = {Auer - Distributed Data Store for Internet of Things Envi.pdf:/Users/d067617/Zotero/storage/VZ5SVMJX/Auer - Distributed Data Store for Internet of Things Envi.pdf:application/pdf;Full Text:/Users/d067617/Zotero/storage/NVRJDELF/Auer - 2017 - Distributed data store for internet of things envi.pdf:application/pdf;Snapshot:/Users/d067617/Zotero/storage/6XQFPHQD/9597.html:text/html},
}

@online{noauthor_semantic_nodate,
	title = {Semantic Web - W3C},
	url = {https://www.w3.org/standards/semanticweb/},
	urldate = {2021-11-30},
	file = {Semantic Web - W3C:/Users/d067617/Zotero/storage/YUSACL64/semanticweb.html:text/html},
}